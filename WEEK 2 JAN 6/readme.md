# WEEK 2
## Session 1: Practical Deep Learning

[https://github.com/fastai/fastai

[https://goo.gl/NNRmQa

[[http://www.fast.ai

[[[ 1. https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/

[[[[https://github.com/sachinruk/deepschool.io

Using the free and proven Fast.ai materials, this is perfect for beginners in deep learning and machine learning, 
with some prior Python programming experience and high school math knowledge – and it’d get you to a stage where 
you can implement cutting-edge deep learning models, in just 14 weeks! No worries if you have no Python programming
experience, feel free to reach out and we’d be happy to advise on what you can use in the weeks leading up to the 
start date to prepare – you can certainly get up to speed if you work hard in these few weeks, but time is running 
short so get started now!

We will watch the lectures as a group, stop the video for discussion at any point if anyone has a question, and also 
breakout into small groups for the in-lecture exercises – removing any obstacles along the way, making sure that you 
can progress through the course confidently if you stick with us – that’s our commitment to you for your time investment!

## Session 2: Deep Learning Theory

[https://stats385.github.io

[https://goo.gl/fzHcYM

We start off with materials from the Stanford STAT385 course on Theories of Deep Learning. For this particular session, 
the true value of the physical meetup lies in discussing the theoretically-dense research paper readings.

Participants are expected to have viewed the lecture video for the week beforehand, and each participant will take charge 
of being the expert authority on one of the readings for the week in the discussion by having thoroughly read and researched 
it, to make the best use of everyone’s time. You can help each other prepare better by posting your questions on specific 
parts of the papers using the Nurture.AI platform’s highlight-commenting function.


## Session 3a: Reinforcement Learning

[http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html
[[http://rll.berkeley.edu/deeprlcourse/

We start off with materials from David Silver’s UCL/DeepMind Reinforcement Learning course, before continuing with UC Berkeley
CS294 Deep Reinforcement Learning. We will view the lecture as a group, stop the video for discussion at any point if anyone 
has a question, and breakout into small groups to discuss papers mentioned. We will then end off with code practice on 
implementing the techniques covered in the session, which can then be completed over the week.

## Session 3b: Convolutional Neural Networks for Visual Recognition

[http://cs231n.stanford.edu
[[

Covering the material in Stanford’s CS231n Spring 2017 course headed by Prof Fei-Fei Li (Chief AI Scientist of Google Cloud, 
Director of Stanford AI Lab), we will take the first 1.5 hours to view and discuss the lecture together. We will take another 
half an hour to discuss the specifics of the paper readings for the week and clarify questions. The last hour will be dedicated
to kicking off the participant’s implementation of the models discussed, which can be completed over the following week. 
This session will cover topics like image classification, object detection, image caption, visual question answering, feature 
visualisation and adversarial training.For ease of the facilitator in-charge’s preparation for any particular week, 
participants are encouraged to read the papers beforehand and post questions on specific parts of the papers using the Nurture.
ai platform’s highlight-commenting function.

## Session 3c: Natural Language Processing with Deep Learning

[http://web.stanford.edu/class/cs224n/

Covering the material in Stanford’s CS224n Winter 2017 course taught by Professor Christopher Manning and Richard Socher 
(Chief Scientist of Salesforce), we will take the first 1.5 hours to view and discuss the lecture together. We will take 
another half an hour to discuss the specifics of the paper readings for the week and clarify questions. The last hour will 
be dedicated to kicking off the participant’s implementation of the models discussed, which can be completed over the following
week. This session will cover topics like word vector representations, dependency parsing, recurrent neural networks and 
language models, machine translation, attention models, tree recursive neural networks, and speech processing.

For ease of the facilitator in-charge’s preparation for any particular week, participants are encouraged to read the papers 
beforehand and post questions on specific parts of the papers using the Nurture.ai platform’s highlight-commenting function.








