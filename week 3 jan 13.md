In order to cater to a diverse audience, there will be 2 sessions every Saturday – you can attend both, 
one of them or none, it’s totally up to you! If you don’t want to attend the sessions, throughout the 
day there will be open hacking on creating open-source code implementations of the top research paper 
pre-prints that week. Or use that time to catch-up on lectures and readings (Afternoon sessions will be more
focused towards demo and hands on Coding !) while discussing with peers.
[http://forums.fast.ai/t/wiki-lesson-2/9399

# Session 1: Video Lecture Synopsis and Discussion
## 1) Practical Deep Learning (Fast.ai) : Lecture 2
Video : [https://youtu.be/JNxcznsrRb8
Wiki : [http://forums.fast.ai/t/wiki-lesson-2/9399

## 2) CS231n : (Mandatory for guys interested in Computer Vision)
Lect 1 : [https://www.youtube.com/watch?v=vT1JzLTH4G4 (Recommended for Beginners)
Lect 2 : [https://www.youtube.com/watch?v=OoUX-nOEjG0
Lect 3 : [https://www.youtube.com/watch?v=h7iBpEHGVNc

## 3) CS224d : (Mandatory for guys interested in NLP)
Lect 1 : [https://www.youtube.com/watch?v=OQQ-W_63UgQ ( Recommended for Beginners)
Lect 2 : [https://www.youtube.com/watch?v=ERibwqs9p38

## 4) Reinforcement Learning: Will be discussed based on the response from the upcoming meetup. For ease of the facilitator 
in-charge’s preparation for any particular week, participants are encouraged to watch the lectures beforehand and post 
questions on specific parts of the lectures using the Nurture.ai platform’s highlight-commenting function.

# Assignments/Tasks

Task 1 : Multi-Class Classification : (Trashnet)

Link : [https://github.com/garythung/trashnet
Dataset Link: [https://drive.google.com/drive/folders/0B3P9oO5A3RvSUW9qTG11Ul83TEE

Use the Dataset-Resized.zip for the dataset.
Please Compare your performance with the authors performance. Write a Brief description about how you 
did it ? Task 2 : Theory Questions


1) Similarity and Difference Between Domain Adaptation and Transfer Learning?
2) What is Bias? How does it affect the performance of the model?
3) How does lr_find() work ? (If Interested)


cycle multiplyer ------

Process 

input data 
data agumentation 
find learning rate 
pre compute = true 
train last layer 

computer vision is amalgation of many domain,it works on statistical computation 

CNN --- segmentation task 

## Image classification pipeline 

challanges: view point varation , background variation 

collect a dataset of images and label


nearest neighbour classifier - distance metric to compare distance 

value of k
distance metric
l2 eculadian distance 

setting hyperparameters (not recommended)
choose hyperparameters
split train and test choose hypermeters 
split data into train val and test  choose parameter on value and evaluate on test 
cross validation  (does not work always) not good for timeseries 

k-nearest on image never used ---curse of dimensanality 

In a normal 

### parameteric approach 

image ----f(x,w)----10 numbers giving class scores 

linear classifiers 

interpreating a linear classifier -- hard 


## NLP 

use WordNET

word2vec 

king - man + women = queen 

huge splash in NLP world 
word2vec : learn word vector vm from its 

there are two vectors for every words 
input and output 

NLP usage -- chatbots(neural network RNN), google search,sentiment analysis(bag of words), question and answering(regular expression)

words are made of morphemes 
parsing for sentence structure 

earlier alg on bag of words  are discarded 

how do we reperesent the meaning of words 

how do we have usable meaning in a computer 

use wordnet a resource containing lists of synonym sets and hypernyms(its arelationship)

problem with wordnet ---

# feature engeneering for image ....
why do we do normalization ?

Whats the best activation function?
transformation with normalization 
resizing 
tunning the hyperparameter--- [http://neupy.com/2016/12/17/hyperparameter_optimization_for_neural_networks.html
How to choose hyperparameter?
  grid based approach
  split the data into train and test 80 to 20
  
  where do we use crossvalidation 
  small datasets

how do u reduce overfitting 
regularization --- add penalty to the weight 

what u do when there is underfitting?---- [https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/

add more data....

* mila labs --- pytorch ---
 https://github.com/mila-udem/welcome_tutorials/tree/master/pytorch
 https://github.com/mila-udem/welcome_tutorials/blob/master/pytorch/1.%20The%20Torch%20Tensor%20Library%20and%20Basic%20Operations.ipynb
 
 * hyperparameter-optimization----[https://ai6forums.nurture.ai/t/best-practices-for-hyperparameter-optimization/42


















